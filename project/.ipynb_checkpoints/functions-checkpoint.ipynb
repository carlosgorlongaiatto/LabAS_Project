{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a5672509-7b89-4fee-9afb-6b9058dfb11e",
    "deepnote_cell_height": 82,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00001-d8dfb83c-ea72-4992-8044-6195561c7d8c",
    "deepnote_cell_height": 423,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 42,
    "execution_start": 1656421234025,
    "source_hash": "9d07d35",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot frequency for each class\n",
    "plot_label_freq <- function(dataset) {\n",
    "\n",
    "    options(repr.plot.width = 15, repr.plot.height = 5)\n",
    "    par(mfrow = c(1, 3))\n",
    "\n",
    "    col <- brewer.pal(max(c(8, length(label_list))), 'Dark2')\n",
    "\n",
    "    for (i in 1:3) {\n",
    "\n",
    "        label_freq <- dataset[[i]] %>% \n",
    "            group_by(Labels) %>%\n",
    "            summarise(counts = length(Labels))\n",
    "\n",
    "        barplot(label_freq[[2]]/sum(label_freq[[2]]), names.arg = label_freq[[1]], col = col,\n",
    "            main = names(dataset)[i], xlab = 'label', ylab = 'frequency [%]',\n",
    "            cex.lab = 1.5, cex.axis = 1.5, cex.names = 1.5, cex.main = 2)\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00002-3e26cba4-baa7-4749-98b6-0272f5471d18",
    "deepnote_cell_height": 441,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1656421234111,
    "source_hash": "7b2212b2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define function to tokenize document (bag of words model)\n",
    "tokenize <- function(document) {\n",
    "\n",
    "    # lowercase\n",
    "    temp <- tolower(document)\n",
    "\n",
    "    # remove everything that is not a letter\n",
    "    temp <- str_replace_all(temp, '[^a-z\\\\s]', ' ')\n",
    "\n",
    "    # shrink down to just one white space\n",
    "    temp <- str_replace_all(temp,'[\\\\s]+', ' ')\n",
    "\n",
    "    # split it\n",
    "    temp <- str_split(temp, ' ')[[1]]\n",
    "    \n",
    "    # remove empty characters\n",
    "    temp <- temp[!(temp %in% '')]\n",
    "\n",
    "    return(temp)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00003-bbb7000f-ff6d-415a-b85e-f4a52da1e0e3",
    "deepnote_cell_height": 279,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1656421234160,
    "source_hash": "b0d6dc44",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaning <- function(document) {\n",
    "\n",
    "    # remove stop words\n",
    "    stop_words <- unique(str_split(paste0(stopwords(), collapse = ' '), '[\\\\s|\\']')[[1]])\n",
    "    temp <- document[!(document %in% stop_words)]\n",
    "\n",
    "    # remove single letters\n",
    "    temp <- temp[!(temp %in% letters)]\n",
    "\n",
    "    return(temp)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00004-60a8415e-e593-46f3-8a01-611d970cec37",
    "deepnote_cell_height": 333,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1656421234161,
    "source_hash": "d082d775",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_processing <- function(document, CLEAN = TRUE, LEM = TRUE) {\n",
    "\n",
    "    # transform string in tokens\n",
    "    document <- tokenize(document)\n",
    "\n",
    "    # clean tokens\n",
    "    if (CLEAN) { document <- cleaning(document) }\n",
    "\n",
    "    # lemmatize tokens\n",
    "    if (LEM) { document <- lemmatize_words(document) }\n",
    "\n",
    "    return(document)\n",
    "}\n",
    "\n",
    "v_pre_processing <- Vectorize(pre_processing, vectorize.args = c('document'), USE.NAMES = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00005-b6f7dfd7-366e-4aad-9694-f9271b77a61e",
    "deepnote_cell_height": 225,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1656421234162,
    "source_hash": "b1c35a88",
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_vocabulary <- function(train) {\n",
    "\n",
    "    # join every list of tokens into a unique list\n",
    "    res <- do.call(c, train$Tokens)\n",
    "\n",
    "    # create the vocabulary of words of the training set\n",
    "    return(sort(unique(res)))\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00006-d0da7faf-9d6d-4d4d-925b-cb91dd7a5f11",
    "deepnote_cell_height": 1017,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1656421234191,
    "source_hash": "873cb46b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_mutual_information <- function(train, vocabulary) {\n",
    "\n",
    "    # mutual information\n",
    "    mutual_information <- list()\n",
    "    \n",
    "    # function to count number of documents containing a given token\n",
    "    count_documents <- function(token, documents) {\n",
    "\n",
    "        counts <- sum(sapply(documents, function(x) token %in% x))\n",
    "        return(counts)\n",
    "\n",
    "    }\n",
    "                \n",
    "    v_count_documents <- Vectorize(count_documents, vectorize.args = c('token'), USE.NAMES = FALSE)\n",
    "\n",
    "    for (label in label_list) {\n",
    "\n",
    "        # number of documents that contain token t and have label l\n",
    "        N_11 <- v_count_documents(vocabulary, documents = train$Tokens[train$Labels == label])\n",
    "        # number of documents that do not contain token t and have label l\n",
    "        N_01 <- nrow(train[train$Labels == label,]) - N_11\n",
    "\n",
    "        # number of documents that contain token t and do not have label l\n",
    "        N_10 <- v_count_documents(vocabulary, documents = train$Tokens[train$Labels != label])\n",
    "        # number of documents that do not contain token t and do not have label l\n",
    "        N_00 <- nrow(train[train$Labels != label,]) - N_10\n",
    "\n",
    "        # total number of documents\n",
    "        N <- N_11 + N_01 + N_10 + N_00\n",
    "\n",
    "        # log losses\n",
    "        log_loss_11 <- ifelse(N_11 > 0, log2(N*N_11/((N_10 + N_11)*(N_01 + N_11))), 0)\n",
    "        log_loss_01 <- ifelse(N_01 > 0, log2(N*N_01/((N_00 + N_01)*(N_01 + N_11))), 0)\n",
    "        log_loss_10 <- ifelse(N_10 > 0, log2(N*N_10/((N_10 + N_11)*(N_00 + N_10))), 0)\n",
    "        log_loss_00 <- ifelse(N_00 > 0, log2(N*N_00/((N_00 + N_01)*(N_00 + N_10))), 0)\n",
    "        \n",
    "        # mutual information\n",
    "        MI <- (N_11/N)*log_loss_11 +\n",
    "            (N_01/N)*log_loss_01 + \n",
    "            (N_10/N)*log_loss_10 + \n",
    "            (N_00/N)*log_loss_00\n",
    "\n",
    "        # add names\n",
    "        names(MI) <- vocabulary\n",
    "\n",
    "        # add mutual information to the list\n",
    "        mutual_information[[paste0('Label_', label)]] <- MI\n",
    " \n",
    "    }\n",
    "\n",
    "    return(mutual_information)\n",
    "         \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00007-12541564-b395-4823-9b5e-9084a44a705d",
    "deepnote_cell_height": 963,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1656421234192,
    "source_hash": "320e6e2a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search <- function(train, val, pp_grid, k_grid) {\n",
    "\n",
    "    # evaluation grid\n",
    "    evaluation_grid <- matrix(0, nrow = length(pp_grid), ncol = length(k_grid))\n",
    "\n",
    "    for (i in 1:length(pp_grid)) {\n",
    "\n",
    "        # pre-process documents in training set\n",
    "        train$Tokens <- v_pre_processing(train$Text, CLEAN = pp_grid[[i]][1], LEM = pp_grid[[i]][2])\n",
    "\n",
    "        # make vocabulary\n",
    "        vocabulary <- make_vocabulary(train)\n",
    "        \n",
    "        # mutual information\n",
    "        mutual_information <- get_mutual_information(train, vocabulary)\n",
    "\n",
    "        for (j in 1:length(k_grid)) {\n",
    "            \n",
    "            # feature selection\n",
    "            k <- k_grid[j]\n",
    "            res <- features_selection(mutual_information, k)\n",
    "\n",
    "            selected_features <- res$selected_features\n",
    "            vocabulary <- res$vocabulary\n",
    "            \n",
    "            # learning model\n",
    "            res <- learning_model(train, vocabulary)\n",
    "\n",
    "            conditional_probs <- res$conditional_probs\n",
    "            priors <- res$priors\n",
    "            tot_tokens_per_label <- res$tot_tokens_per_label\n",
    "            \n",
    "            # predict\n",
    "            true_labels <- val$Labels\n",
    "            predicted_labels <- v_predict(val$Text, \n",
    "                                vocabulary = vocabulary,\n",
    "                                conditional_probs = conditional_probs, priors = priors,\n",
    "                                tot_tokens_per_label = tot_tokens_per_label,\n",
    "                                CLEAN = pp_grid[[i]][1], LEM = pp_grid[[i]][2])\n",
    "            \n",
    "            # evaluate\n",
    "            res <- evaluate(true_labels, predicted_labels)\n",
    "            accuracy <- res$accuracy\n",
    "            evaluation_grid[i,j] <- accuracy\n",
    "\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return(evaluation_grid)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00008-fbe413df-1d69-462e-a4ef-981ff32993eb",
    "deepnote_cell_height": 639,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19,
    "execution_start": 1656421234194,
    "owner_user_id": "66111578-48f6-4041-8347-ed013a63b10d",
    "source_hash": "ea302c59",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_grid_search <- function(pp_grid, k_grid, evaluation_grid) {\n",
    "    \n",
    "    options(repr.plot.width = 14, repr.plot.height = 7)\n",
    "\n",
    "    col <- brewer.pal(max(c(8, length(label_list))), 'Dark2')\n",
    "\n",
    "    for (i in 1:length(pp_grid)) {\n",
    "\n",
    "        if (i == 1) {\n",
    "            plot(k_grid, evaluation_grid[1,], type = 'b', pch = 16, lwd = 2, col = col[i],\n",
    "            xlim = c(0,1), ylim = c(min(evaluation_grid)-0.1, max(evaluation_grid)+0.1),\n",
    "            main = 'Grid search', xlab = 'k', ylab = 'accuracy',\n",
    "            cex.lab = 1.25, cex.axis = 1, cex.main = 1.5)\n",
    "        } else {   \n",
    "            points(k_grid, evaluation_grid[i,], type = 'b', pch = 16, lwd = 2, col = col[i])\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "    grid(lty = 2)\n",
    "\n",
    "    legend(x = 'bottomright',\n",
    "        inset = 0.02,\n",
    "        legend = c('no pre-processing', 'cleaning and lemmatizing'),\n",
    "        lty = rep(1,2),\n",
    "        lwd = rep(1,2),\n",
    "        col = col[1:length(pp_grid)],\n",
    "        #bty = 'n',\n",
    "        cex = 1)\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00009-1e2e5199-a18a-46bb-862f-9f41665a299b",
    "deepnote_cell_height": 567,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1656421234215,
    "source_hash": "a0af6858",
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_selection <- function(mutual_information, k) {\n",
    "\n",
    "    # selected features\n",
    "    selected_features <- list()\n",
    "\n",
    "    for (label in label_list) {\n",
    "\n",
    "        # sort\n",
    "        MI <- sort(mutual_information[[paste0('Label_', label)]], decreasing = T)\n",
    "\n",
    "        # select k [%] features\n",
    "        MI <- MI[1:floor(k*length(MI))]\n",
    "\n",
    "        # add selected features to the list\n",
    "        selected_features[[paste0('Label_', label)]] <- MI\n",
    "\n",
    "    }\n",
    "\n",
    "    # join every named vector into a unique list\n",
    "    res <- do.call(c, unname(selected_features))\n",
    "\n",
    "    # create the new vocabulary of tokens of the training set after feature selection\n",
    "    vocabulary <- sort(unique(names(res)))\n",
    "\n",
    "    return(list(selected_features = selected_features,\n",
    "                vocabulary = vocabulary))\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00010-f2af11eb-b85b-4bd1-8114-dec2a860d510",
    "deepnote_cell_height": 639,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1656421234231,
    "owner_user_id": "0a06ca46-5b60-4cbc-85be-15b044414a83",
    "source_hash": "7c4469d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_MI <- function(mutual_information, k, x_legend) {\n",
    "\n",
    "    # plot ordered mutual information for each class\n",
    "    options(repr.plot.width = 14, repr.plot.height = 7)\n",
    "    par(mfrow = c(1, 2))\n",
    "    \n",
    "    col <- brewer.pal(max(c(8, length(label_list))), 'Dark2')\n",
    "\n",
    "    for (label in label_list) {\n",
    "\n",
    "        if ((label %% 2) == 0) {\n",
    "            options(repr.plot.width = 14, repr.plot.height = 7)\n",
    "            par(mfrow = c(1, 2))\n",
    "            }\n",
    "\n",
    "        MI <- mutual_information[[paste0('Label_', label)]]\n",
    "        MI[is.nan(MI)] <- 0\n",
    "        MI <- sort(MI, decreasing = T)\n",
    "        plot(1:length(MI), MI, ylim = c(0, 0.005), type = 'l', lwd = 2, col = col[1],\n",
    "            main = paste0('Label_', label), xlab = 'token index', ylab = 'MI',\n",
    "            cex.lab = 1.5, cex.axis = 1.5, cex.main = 2)\n",
    "        abline(v = floor(k*length(MI)), lwd = 2, lty = 2, col = col[2])\n",
    "\n",
    "        legend(x = x_legend, y = 1*0.005,\n",
    "        legend = c('mutual information', 'k*len(vocabulary)'),\n",
    "        lty = rep(1,2),\n",
    "        lwd = rep(2,2),\n",
    "        col = c(col[1], col[2]),\n",
    "        bty = 'n',\n",
    "        cex = 1.3)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "b3b99a1f453f4b56a35e7be43dc5b4f0",
    "deepnote_cell_height": 387,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1656421234274,
    "source_hash": "62e943",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize top 10 features for each label\n",
    "get_feature_ranking <- function(selected_features, label_names) {\n",
    "\n",
    "    feature_ranking <- list()\n",
    "\n",
    "    for (label in label_list) {\n",
    "\n",
    "        # select token sorted by descending mutual information for one label\n",
    "        feature_ranking[[label+1]] <- names(selected_features[[paste0('Label_', label)]])\n",
    "    \n",
    "    }\n",
    "\n",
    "    feature_ranking <- as.data.frame(feature_ranking)\n",
    "    colnames(feature_ranking) <- label_names\n",
    "\n",
    "    return(feature_ranking)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00011-bec601b5-d52d-4af4-a571-4cf2a888ba0e",
    "deepnote_cell_height": 927,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1656421234275,
    "source_hash": "2707d086",
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_model <- function(train, vocabulary) {\n",
    "\n",
    "    # create dataframe of conditional probabilities\n",
    "    conditional_probs <- data.frame(Token = vocabulary)\n",
    "    priors <- NULL\n",
    "    tot_tokens_per_label <- NULL\n",
    "\n",
    "    # number of training data\n",
    "    N <- nrow(train)\n",
    "\n",
    "    # function to compute unnormalized conditional probability with Laplace smoothing\n",
    "    conditional_prob <- function(token, tokens_list){\n",
    "\n",
    "        n_token <- sum(tokens_list == token) + 1\n",
    "        return(n_token)\n",
    "\n",
    "    }\n",
    "    \n",
    "    v_conditional_prob <- Vectorize(conditional_prob, vectorize.args = c('token'), USE.NAMES = FALSE)\n",
    "\n",
    "    for (label in label_list) {\n",
    "        \n",
    "        # create list of tokens grouped by label\n",
    "        tokens_list <- do.call(c, train$Tokens[train$Labels == label])\n",
    "\n",
    "        # count total number of token in label l\n",
    "        tot_tokens <- length(tokens_list)\n",
    "\n",
    "        # save number of tokens per label (will be used in the test set)\n",
    "        tot_tokens_per_label  <- c(tot_tokens_per_label, tot_tokens + length(vocabulary))\n",
    "\n",
    "        # calculate the conditional probability function for every token of the vocabulary\n",
    "        conditional_probs[[paste0('Label_', label)]] <- v_conditional_prob(conditional_probs$Token, tokens_list=tokens_list)\n",
    "\n",
    "        # normalize the conditional probabilities\n",
    "        normalization <- (tot_tokens + length(vocabulary))\n",
    "        conditional_probs[[paste0('Label_', label)]] <- conditional_probs[[paste0('Label_', label)]]/normalization\n",
    "\n",
    "        # calculate prior for the labels\n",
    "        N_l <- sum(train$Labels == label)\n",
    "        priors <- c(priors, N_l/N)\n",
    "    }\n",
    "\n",
    "    return(list(conditional_probs = conditional_probs,\n",
    "                priors = priors,\n",
    "                tot_tokens_per_label = tot_tokens_per_label))\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "00012-ff6c9557-add9-495e-a052-9e9e3377b78d",
    "deepnote_cell_height": 585,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1656421234277,
    "source_hash": "2b55bac",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict <- function(document, vocabulary,\n",
    "                    conditional_probs, priors, tot_tokens_per_label,\n",
    "                    CLEAN = TRUE, LEM = TRUE){\n",
    "\n",
    "    # pre-process document\n",
    "    tokens_in_document <- pre_processing(document, CLEAN = CLEAN, LEM = LEM)\n",
    "\n",
    "    # select conditional probabilities of token in document\n",
    "    conditional_probs <- conditional_probs[vocabulary %in% tokens_in_document,]\n",
    "\n",
    "    # calculate log-likelihood of the document for each label\n",
    "    log_likelihoods <- colSums(log(conditional_probs[, 2:(1+length(label_list))]))\n",
    "\n",
    "    # calculate log-posterior for each label \n",
    "    log_posteriors <- log_likelihoods + log(priors) \n",
    "\n",
    "    # count the number of tokens not in the vocabulary\n",
    "    n_unseen_tokens <- length(setdiff(tokens_in_document, vocabulary))\n",
    "\n",
    "    # add the log-posterior for the tokens not in the vocabulary\n",
    "    log_posteriors <- log_posteriors - n_unseen_tokens*log(tot_tokens_per_label)\n",
    "\n",
    "    predicted_labels <- (which.max(log_posteriors) - 1)\n",
    "\n",
    "    return(predicted_labels)\n",
    "\n",
    "}\n",
    "\n",
    "v_predict <- Vectorize(predict, vectorize.args = c('document'), USE.NAMES = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "00013-62a898ac-0db8-432d-a780-7f3fc07d3298",
    "deepnote_cell_height": 225,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1656421234314,
    "source_hash": "95449adc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_confusion_matrix <- function(true_labels, predicted_labels) {\n",
    "\n",
    "    # confusion matrix\n",
    "    cm <- confusionMatrix(as.factor(predicted_labels),\n",
    "                        as.factor(true_labels),\n",
    "                        dnn = c('Prediction', 'Reference'))\n",
    "    return(cm)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "00014-727370fb-4c36-4ca6-8972-1258719bdb93",
    "deepnote_cell_height": 531,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1656421234315,
    "source_hash": "60cbdb3f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_micro_f1_measure <- function(true_labels, predicted_labels) {\n",
    "\n",
    "    label_count = aggregate(true_labels, by = list(true_labels), FUN = length)\n",
    "    names(label_count) <- c('Labels', 'Count')\n",
    "\n",
    "    # total true positive\n",
    "    tot_TP <- 0\n",
    "    # total false positive\n",
    "    tot_FP <- 0\n",
    "    # total false negative\n",
    "    tot_FN <- 0\n",
    "\n",
    "    for (label in label_count$Labels) {\n",
    "\n",
    "        tot_TP <- tot_TP + sum(predicted_labels[true_labels == label] == label)\n",
    "        tot_FP <- tot_FP + sum(predicted_labels[true_labels != label] == label)\n",
    "        tot_FN <- tot_FN + sum(predicted_labels[true_labels == label] != label)\n",
    "\n",
    "    }\n",
    "\n",
    "    micro_precision = tot_TP/(tot_TP + tot_FP)\n",
    "    micro_recall = tot_TP/(tot_TP + tot_FN)\n",
    "\n",
    "    return(2*(micro_precision*micro_recall)/(micro_precision + micro_recall))\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "00015-ba83a23e-5400-4d82-99be-31345d13809c",
    "deepnote_cell_height": 153,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 16,
    "execution_start": 1656421234336,
    "source_hash": "d2104a68",
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_accuracy <- function(true_labels, predicted_labels) {\n",
    "\n",
    "    return(sum(true_labels == predicted_labels)/length(true_labels))\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "00016-aa56367d-3e6f-4019-b402-1737c71bd66d",
    "deepnote_cell_height": 189,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1656421234352,
    "source_hash": "c3ff6dd9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate <- function(true_labels, predicted_labels) {\n",
    "\n",
    "    return(list(confusion_matrix = get_confusion_matrix(true_labels, predicted_labels),\n",
    "                micro_f1_measure = get_micro_f1_measure(true_labels, predicted_labels),\n",
    "                accuracy = get_accuracy(true_labels, predicted_labels)))\n",
    "                \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "00017-cab21900-1d44-4522-9d45-ce8a7958e96b",
    "deepnote_cell_height": 495,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1656421234354,
    "owner_user_id": "4056cfae-e546-4483-b374-f55676543ebc",
    "source_hash": "b9e84687",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "plot_confusion_matrix <- function(cm) {\n",
    "\n",
    "    options(repr.plot.width = 7, repr.plot.height = 7)\n",
    "\n",
    "    col <- brewer.pal(max(c(8, length(label_list))), 'Dark2')\n",
    "\n",
    "    # divide each column by its sum\n",
    "    plt <- as.data.frame(round(sweep(cm$table, 2, colSums(cm$table), FUN = '/'), 2))\n",
    "    plt$Prediction <- factor(plt$Prediction, levels = rev(levels(plt$Prediction)))\n",
    "\n",
    "    ggplot(plt, aes(Prediction, Reference, fill = Freq)) +\n",
    "        geom_tile() + geom_text(aes(label = Freq), size = 7) +\n",
    "        scale_fill_gradient(low = 'white', high = col[1]) +\n",
    "        labs(title = 'Confusion matrix', x = 'reference', y = 'prediction') +\n",
    "        scale_x_discrete(labels = as.character(label_list)) +\n",
    "        scale_y_discrete(labels = as.character(rev(label_list))) +\n",
    "        theme(axis.text.x = element_text(size = 14),\n",
    "            axis.text.y = element_text(size = 14),  \n",
    "            axis.title.x = element_text(size = 16),\n",
    "            axis.title.y = element_text(size = 16),\n",
    "            title = element_text(size = 18)) +\n",
    "        theme(legend.position = 'none')\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "00018-fa5f4bd3-41a2-425c-b320-c2ff66e76b3b",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1656421234407,
    "source_hash": "64a6331a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "save(list = ls(all=TRUE), file = 'functions')"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "9fd1e063-1313-484c-90d1-9a31bce80f91",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
